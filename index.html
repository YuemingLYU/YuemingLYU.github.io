<!DOCTYPE html>

<html><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
    
    <link rel="stylesheet" type="text/css" href="./main.css">
    <title>Yueming Lyu</title>
    <!--<base href="https://YuemingLYU.github.io/index.html">--><base href=".">
</head>

<body>
<h1 style="padding-left: 0.5em">Yueming Lyu</h1><hr><table summary="Table for page layout." id="tlayout">
<tbody><tr valign="top">

<td id="layout-menu">
    <div class="menu-item"><a href="https://YuemingLYU.github.io/index.html" class="current">Home</a></div>

</td>
<td id="layout-content">

    <h1 style="margin-top: 0em">Home</h1><br>
 

    <table class="imgtable"><tbody><tr valign="top">
        <!--<td><img src="YuemingLyu.jpg" alt="Yueming Lyu" /></td>-->
        <td align="left">
            <p><span style="font-size: 110%"><b>Yueming Lyu</b></span></p>
            <p>
                Ph.D. student<br>
                <a href="https://www.uts.edu.au/research-and-teaching/our-research/australian-artificial-intelligence-institute" target="_blank">Australian Artificial Intelligence Institute (AAII)</a>,<br>
                <a href="https://www.uts.edu.au/" target="_blank">University of Technology Sydney (UTS)</a>
            </p>

            <p>
                E-mail: yueminglyu [at] gmail.com <br>
                <a href="https://scholar.google.com/citations?user=uQXB6-oAAAAJ&hl=en" target="_blank">[Google Scholar]</a>
               
            </p>
        </td>
    </tr></tbody></table>
	
	
	 <div>
        <h2><hr><a name="biography"></a>Brief Biography</h2>
        <ul>
            Yueming Lyu is currently a Ph.D. student at <a href="https://www.uts.edu.au/research-and-teaching/our-research/centre-artificial-intelligence" target="_blank">Australian Artificial Intelligence Institute</a> in <a href="https://www.uts.edu.au/" target="_blank">University of Technology Sydney</a>(UTS),  supervised by <a href="https://www.uts.edu.au/staff/ivor.tsang" target="_blank">Prof. Ivor W. Tsang</a>. Before that, he was a research intern at Tencent AI Lab, working on reinforcement learning (RL) with <a href="http://pengsun.github.io/" target="_blank">Dr.Peng Sun</a> and optimization with <a href="https://sites.google.com/site/mathshenli/home" target="_blank">Dr. Li Shen</a>. He received his B.Eng degree and M.Eng degree in Computer Science and Technology from <a href="https://www.scut.edu.cn/en/" target="_blank">South China University of Technology</a>. 
        </ul>
    </div>
	

    <div>
        <h2><hr><a name="research"></a>My Research</h2>

<ul>
	My research interests  lie primarily in the area of <b> statistical machine learning </b> and <b> optimization</b>. I am particularly interested in <b>approximation theory</b>, <b>learning theory</b>, and <b>black-box optimization</b>. I am happy working on developing simple, solid and efficient algorithms  for the  following  problems.
</ul>
<ul>
	<li><p>Quasi-Monte Carlo (QMC) and Kernel Methods</p></li>    
		<ul>
			<li><p> QMC theory is a fundamental part of approximation theory. The goal of QMC methods is to design good points set for integral approximation. It can be used in Bayesian Inference and kernel approximation, etc. QMC based feature maps  are promising direction of random feature methods , which can reduce the time and space complexity of kernel methods (e.g., Gaussian Process and SVM). Interestingly, there is a close relationship between random feature maps and neural networks. Besides, QMC methods also have applications in sampling techniques in RL and generative models.</p></li>
						
		</ul> 
	<li><p>Black-box Optimization and Reinforcement Learning (RL)</p></li>
		<ul>
			<li><p> Black-box optimization is a subarea of optimization.  It handles the cases that only function quire can be accessed.  The potential applications include reinforcement learning (RL), engineering design and black-box attack, etc. The goal is to design efficient and theoretical sounded black-box optimization algorithms to improve query efficiency. These algorithms can be used for model-free RL. Moreover, the methodology of black-box optimization is also helpful for designing efficient RL methods.  </p></li>
		</ul>
	<li><p>Robust Learning and Weakly-supervised Learning</p></li>
		<ul>
			<li><p> Both robust learning and weakly-supervised learning are subareas of machine learning. Robust learning and weakly-supervised learning aims at addressing a more practical situation in real-life. The input collection may contain noise; the annotation may be corrupted or even expensive to acquire. It is challenging to develop smart algorithms to handle these cases.  </p></li>
		</ul>
</ul>
</div>

    <div>
        <h2><hr><a name="publications"></a>Selected Recent Publications</h2>
			<ul>
                <li><p> QMC and Kernel Methods: </p></li>
					<ul>
						<li><p> <b>Yueming Lyu</b>, Yuan Yuan and Ivor Tsang. Subgroup-based Rank-1 Lattice Quasi-Monte Carlo. Accepted by <i>Advances in Neural Information Processing Systems</i> (NeurIPS), 2020 </p></li>
						<li><p> <b>Yueming Lyu</b>. <a href="http://proceedings.mlr.press/v70/lyu17a/lyu17a.pdf" target="_blank">Spherical structured feature maps for kernel approximation</a>. In <i>International Conference on Machine Learning</i> (ICML), 2017</p></li>
						
					</ul>
                <li><p> Black-box Optimization and RL: </p></li>
					<ul>
						<li><p> <b>Yueming Lyu</b> and Ivor Tsang. <a href="https://arxiv.org/pdf/1910.04301.pdf" target="_blank">Black-box Optimizer with Implicit Natural Gradient</a>. <i>Preprint</i>. </p></li>
						<li><p> <b>Yueming Lyu</b>, Yuan Yuan and Ivor Tsang. <a href="https://arxiv.org/pdf/1905.10041.pdf" target="_blank">Efficient Batch Black-box Optimization with Deterministic Regret Bounds</a>.  <i>Preprint</i>. </p></li>
						<li><p> Xingrui Yu, <b>Yueming Lyu</b> and Ivor Tsang. <a href="https://arxiv.org/pdf/2006.15061.pdf" target="_blank">Intrinsic Reward Driven Imitation Learning via Generative Model</a>. In <i>International Conference on Machine Learning</i> (ICML), 2020</p></li>
					</ul>
				<li><p> Robust Learning and Weakly-supervised Learning: </p></li>
					<ul>
						<li><p> <b>Yueming Lyu</b> and Ivor Tsang. <a href="https://openreview.net/pdf?id=rkgt0REKwS" target="_blank">Curriculum Loss: Robust Learning and Generalization against Label Corruption</a>. In <i> International Conference on Learning Representations</i> (ICLR), 2020</p></li>
						<li><p> Yuan Yuan, <b>Yueming Lyu</b>, Xi Shen, Ivor Tsang, Dit-Yan Yeung.  <a href="https://openreview.net/pdf?id=HkljioCcFQ" target="_blank">Marginalized average attentional network for weakly-supervised learning</a>. In  International Conference on Learning Representations (ICLR), 2019 </p></li>
						
					</ul>
            </ul>
    </div>

    <div>
        <h2><hr><a name="service"></a>Professional Service</h2>
            <ul>
                <li><p> Conference Reviewer/Program Committee: </p></li>
					<ul>
						<li><p> ICLR-2021, AISTATS 2021, AAAI-2021 </p></li>
						<li><p> NeurIPS-2020, AISTATS 2020, AAAI-2020, ACML-2020 </p></li>
						<li><p> ICML-2019, NeurIPS-2019, AISTATS 2019, ACML-2019 </p></li>
					</ul>
                <li><p> Journal Reviewer: </p></li>
					<ul>
						<li><p> IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI) </p></li>
						<li><p> Machine Learning </p></li>
					</ul>
            </ul>
    </div>



   


</td>
</tr>
</tbody></table>


<script>mendeleyWebImporter = { open: function () { window.postMessage('0.12216999614076118', 'https://YuemingLYU.github.io') } }</script></body></html>
